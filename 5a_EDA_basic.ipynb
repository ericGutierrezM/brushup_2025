{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA on WB pop data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to answer the questions on the board. For each cell:\n",
    "- Can you explain what the code is doing?\n",
    "- Is there anything you can change/ adjust?\n",
    "- Try writing the same or your own version in a new cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember: relative paths are better for collaboration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing with absolute path\n",
    "# you won't be able to run this directly - you can get your equivalent by right-clicking on the csv in your explorer\n",
    "\n",
    "df_direct = pd.read_csv('/Users/margheritaphilipp/Documents/margherita/GitHub/brushup_2025/data/WB_pop_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing with relative path:\n",
    "# if you have saved this file in a folder that has a data subfolder with the same csv inside, you can run this directly \n",
    "\n",
    "# get current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "parent_path = os.path.dirname(cwd)\n",
    "\n",
    "df_og = pd.read_csv(parent_path + '/data/WB_pop_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good practice to make a copy before manipulating - so you can quickly revert to the original without importing again\n",
    "# NB in this notebook we are not yet making changes to the df, so we don't need the copy here\n",
    "df = df_og.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addresses the following questions from class:\n",
    "- Display the head, check for missing values\n",
    "- Find the min and max values - overall and just for 2023\n",
    "- Which countries do they belong to?\n",
    "- Inspect the values in the “Country Code” column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the dimensions (rows and columns) of the data set and display first few rows\n",
    "print(df.shape)\n",
    "\n",
    "# other options:\n",
    "# df.tail(2)\n",
    "# df.sample(4)\n",
    "\n",
    "df_og.head() # default is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes not all columns are visible so it can be useful to get the full list\n",
    "df_og.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while .head() is a ***method*** I apply to the data frame, .shape and .columns are ***attributes*** of the data frame object/ class that I can call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the info method also tells us which columns are present and what data type they contain\n",
    "# we know from the shape attribute that there are 218 rows and it seems that all rows contain data (are non-null), i.e. we don't have missing values\n",
    "\n",
    "df_og.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical summary of the numerical columns - we can already see a suspiciously high maximum value...\n",
    "\n",
    "df_og.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if I just want to find the min and max values for a speficic column:\n",
    "\n",
    "print('mix and max vals for 2023: ', df['2023'].min(), df['2023'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one way to get the whole row for these values is to use loc\n",
    "\n",
    "df_og.loc[df['2023'] == df['2023'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but this method is a bit more elegant and flexible\n",
    "\n",
    "df_og.nlargest(2, '2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og.nsmallest(5, ['2024', '2000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the country column: note that the lentgh of the value counts is 218, same as the number of unique values, so each country only appears once\n",
    "\n",
    "print(df_og['Country Name'].nunique()) # same as len(df['Country Name'].unique())\n",
    "\n",
    "print(df_og['Country Name'].unique())\n",
    "\n",
    "df_og['Country Name'].value_counts() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brushup-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
